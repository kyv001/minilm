一个小型语言模型，参考了karpathy/nanoGPT的设计。
自带了使用万卷数据集进行预训练的部分代码，可惜笔记本性能低下无法自行完成训练。
如何自行训练？
1、将https://opendatalab.com/OpenDataLab/WanJuan1_dot_0/tree/main/raw/nlp/CN 中ChinaNews-cn文件夹下所有文件下载到WanJuan-News文件夹下、把WebText-cn文件夹下所有文件下载到WanJuan-Webtext文件夹下；
2、安装requirements.txt内所有包并将config.py中USE_TORCH2改为True，如果无法安装则安装requirements_old.txt并保留USE_TORCH2为False；
3、如果只有一张显卡，运行python3 llm.py；如果有不止一张显卡，运行torchrun --standalone --nproc_per_node={显卡数量} llm.py。

训练完毕，如何推理？
1、选择目录中整数部分最大的pth文件，将其文件名填入config.py的PRETRAINED_STATE_DICT_PATH变量的双引号中；
2、修改config.py中的TRAIN变量为False；
3、运行python llm.py以进行推理（效果不会很好）；

为什么这b模型不收敛？？？？